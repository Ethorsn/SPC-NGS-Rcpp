\Sexpr{set_parent('../MainThesis.Rnw')}

<<Loads,echo=FALSE>>=
load("../Data/LambdaAndXtable.Rdata")
load("../Data/ICdata.Rdata")

K <- 100
OrgOrder <- colnames(TransformedData)
# divide by a constant!
TransformedData[,1:ncol(TransformedData) %in% grep("mean",OrgOrder)] <- TransformedData[,1:ncol(TransformedData) %in% grep("mean",OrgOrder)]/K
n <- nrow(TransformedData)
Sigma0 <- var(TransformedData)*(n-1)/n
@
In this section we will present the transformation methods and evaluate the assumption that the process follows a multivariate normal distribution. We will also look upon the autocorrelation and to what extent it is present in the data. However, the autocorrelation should be interpreted with caution. Not only does the assumption of temporal independence depend upon the normality assumption but it also assumes that the timeseries is regular. 

For the variables which have support on the positive real line we will use the Box-Cox transformation, presented in \citet{BoxCox}, i.e.
$$
Z=
\begin{cases}
\frac{X^{\lambda}-1}{\lambda} & \text{for } \lambda \neq 0 \\
\log(X) & \text{else}.
\end{cases}
$$
for transformation. The variables are transformed independently. The parameter $\lambda$ is estimated using the method suggested in \citet{Gurrero}. The Box Cox transformation and the guerro estimation method is implemented in the \texttt{forecast} package. For variables which have limited support on $(0,1)$ we will use the standard normal quantile function as a transformation method. Consider X having support on (0,1), then we have that
$$
Z = \Phi^{-1}(X),
$$
where Y will follow a normal distribution.

Two statistical tests of the normal assumption are presented in Table \ref{TestTable}, performed on the transformed data. Henze-Zirkler's multivariate test of normality, presented in \citet{HenzeZirkler}, shows some evidence against the null that data is not normally distributed. The genaralized Shapiro-Wilk test of normality, presented in \citet{GenShapWilk}, shows no evidence at all.
<<xtableTransofrm,echo=FALSE,results='asis'>>=
library(xtable)
xtable::xtable(data.frame("Test"=c("Henze-Zirkler's","Generalized Shapiro-Wilk"),"P-value"=c(t2@p.value,t4$p.value)), label="TestTable", caption="Two statistical tests of normality, Henze-Zirkler's and a generalized Shapiro-Wilk's test. One out of two tests approves of the normality assumption.")
@
Under the assumption that the transformed data \textit{is} normally distributed, the autocorrelation may be investigated. If the autocorrelation at a given lag is below the standard normal distributions $95\%$ percentile we can assume that the data is independent in time. There are a total of \Sexpr{dim(TransformedData)[2]*(dim(TransformedData)[2]-1)/2} correlation coefficients at each lag to investigate. We will show the proportion of lags which are greater than the standard normal distributions $95\%$ percentile and all autocorrelation coefficients, for a given lag, in a histogram. 
For the HiSeq 6 machine, the proportion of autocorrelation coefficients greater than the normal quantile are seen in Table \ref{ACFtable} for lags one through five. The autocorrelation for the first two lags are shown in Figure \ref{fig:FigureACF}. Under the assumption of normally distributed data, it can be seen that the HiSeq 6 data shows to much autocorrelation to be independent in a temporal manner. However, since the transformed data shows little evidence that it is normally disitributed, any conclusions on the independence between observations in a temporal manner, could be highly inapproriate and inaccurate. Also, we have removed data before transformation which may have created or removed autocorrelation. 

We will also test the assumption that the estimated covariance matrix is a positive definite matrix using the \texttt{is.positive.definite} function from the \texttt{matrixcalc} package. 
<<CovMat, echo=FALSE>>=
bool <- matrixcalc::is.positive.definite(Sigma0)
@
The result from the function is $\Sexpr{bool}$, the estimated covariance matrix is positive definite. 

<<TableACF, results='asis'>>=
library(dplyr)
library(ggplot2)
CalculatePropACF <- function(x,lag){
  
  tmp.strings <- colnames(x)
  
  x.tmp <- x[,order(tmp.strings)]
  
  ACF <- acf(x.tmp, plot=FALSE, lag.max=lag)

  # allocate matrix
  tmp <- matrix(ncol=dim(ACF$acf)[2],nrow=dim(ACF$acf)[3])
  # extract the lag which is supposed to be investigated
  for (i in 1:dim(ACF$acf)[3]){
    # the first element of $acf is equal to the correlation therefore lag+1.
    tmp[i,] <- ACF$acf[lag+1,,i]
  }
  #normal quantile
  limit <- 1.96/sqrt(ACF$n.used)
  
  nom <- which(abs(tmp[upper.tri(tmp, diag=TRUE)])>limit) 
  
  denom <- tmp[upper.tri(tmp, diag=TRUE)] %>% length

  prop <- length(nom)/denom
  return(list("Props"=prop,
              "AutoCorr"=tmp[upper.tri(tmp, diag=TRUE)]
  ))
}
propList <- lapply(1:5,function(x) CalculatePropACF(TransformedData,x))

Proportions <- lapply(1:length(propList), function(x) propList[[x]]$Props) %>% unlist()
AutoCorr <- lapply(1:length(propList), function(x) propList[[x]]$AutoCorr)

x.tabl <- xtable::xtable(data.frame(Lag=1:5,Proportion=Proportions), caption="Proportion of autocorrelation greater than the normal 95 percentile, at lags 1 through 5.", label="ACFtable")
print.xtable(x.tabl,include.rownames = FALSE)

library(gridExtra)

p1<- ggplot(data.frame(x=AutoCorr[[1]])) +
  geom_histogram(aes(x=x)) +
  theme_bw() +
  xlab("value") +
  ggtitle("Autocorrelation, lag 1")
p2 <- ggplot(data.frame(x=AutoCorr[[2]])) +
  geom_histogram(aes(x=x)) +
  theme_bw() +
  xlab("value") +
  ggtitle("Autocorrelation, lag 2") 
@
\begin{center}
<<FigureACF, fig.cap="Distribution of autocorrelation coefficients at lag 1 (left) and lag 2 (right) of the transformed data.", fig.height=3.5>>=
grid.arrange(p1,p2, ncol=2)
@
\end{center}