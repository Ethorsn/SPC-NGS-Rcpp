\documentclass[10pt]{beamer}
%\usepackage[T1]{fontenc}
%\setcounter{secnumdepth}{3}
%\setcounter{tocdepth}{3}
%\usepackage{url}
%\usepackage{graphicx} 
\usepackage{tikz}

\usetheme{Singapore}
\useoutertheme{miniframes,smoothbars}

\begin{document}

\title{Process control in NGS quality control data}  
\subtitle{Master Thesis, Stockholm University}
\author{Erik Thors\'{e}n}
\date{\today} 
<<libsSETUP, message=FALSE, echo=FALSE>>=
library(knitr)
# chunk option set up
opts_chunk$set(echo = FALSE,
               fig.height=4,
               message = FALSE,
               tidy=TRUE)
@
\begin{frame}
\titlepage
\end{frame}

\begin{frame}
  \frametitle{Overview}
  \tableofcontents
\end{frame}

\section{Introduction}
%
% What should be in this section?
% A introduction to the problem
% A introduction on how to solve it
% 
\begin{frame}\frametitle{Aim}
\begin{center}
Construct models which can detect (without our supervision) reduced, or perhaps increased, quality in quality control sequencing data!
\end{center} 
\end{frame}
\begin{frame}\frametitle{Problem description}

\begin{center}
To detect changes and trends in NGS quality control data over time. 
\end{center}

\begin{itemize}
\item Can we deduce a bad/good flowcell from quality control data?
\item Can we detect when the machine is in need of maintainance?
\item If a persistent change occured, can we estimate \textit{when}?
\end{itemize}
\end{frame}


\begin{frame}\frametitle{Types of changes and a solution}
We are interested in the following changes:
\begin{itemize}
\item Transient and large (poor/good sample/flowcell)
\item Persistent and small (ex. machine is in need of maintainance)
\end{itemize}
\pause

\textbf{Solution:}
\begin{center}
\textbf{Statistical process control} and a \textbf{Change-point detection model} 
\end{center}
\end{frame}
<<LoadLibs>>=
library(ggplot2)
library(reshape2)
library(GGally)
library(lubridate)
library(tidyr)
library(dplyr)
library(portes)
library(car) 
library(gridExtra)
library(grid)
library(ggExtra)
library(parallel)
library(xtable)
library(Rcpp)
library(RcppArmadillo)
# load data + functions
# must be run in this order!!!
source("../FunctionsAndRcpp/VizCorFuns.R")
source("../FunctionsAndRcpp/mysqlScript.R")
source("../FunctionsAndRcpp/BotlvlSeriesExtraction.R")
###################### Hadley Wickhams function
grid_arrange_shared_legend <- function(...) {
    plots <- list(...)
    g <- ggplotGrob(plots[[1]] + theme(legend.position="bottom"))$grobs
    legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
    lheight <- sum(legend$height)
    grid.arrange(
        do.call(arrangeGrob, lapply(plots, function(x)
            x + theme(legend.position="none"))),
        legend,
        ncol = 1,
        heights = unit.c(unit(1, "npc") - lheight, lheight))
}
#######################
N <- unique(All.df$flowcell_id) %>% length()
Numb2012 <- filter(All.df, year(Date) == 2012) %>% select(flowcell_id) %>% unique() %>% nrow()
First.date <- first(df.sample.results$Date)
@
% A extended EDA, what should be here?
% Everything that is done for the HiSeq 6 and more!

\section[SPC - models]{Statistical process control - Introduction: Terminology and models}

\begin{frame}\frametitle{Distribution assumption, Machine profile}
\textbf{Assumption 1}: Data follows a multivariate normal distribution.
\begin{center}
$\mathbf{X} \sim \mathcal{N}_p(\boldsymbol{\mu}_0, \Sigma_0)$.
\end{center}
In control machine profile: $\boldsymbol{\mu}_0,\; \Sigma_0$. Machine profile based on quality control data.

\textbf{Assumption 2}: Observations are independent!
\end{frame}

\begin{frame}\frametitle{Statistical process control - Hotellings, MCUSUM, CPD}
Monitor profile $\boldsymbol{\mu}_0, \Sigma_0$ with models:
 \begin{itemize}
 \item Hotelling $T^2$ statistic - large and transient changes (due to poor samples)
 \item MCUSUM scheme - small and persistent changes (due to new parts)
 \item Change point detection (CPD) - \textit{when} did the persistent change occur?
 \end{itemize}
All control charts are directionally invariant $\rightarrow$ only matters that a change occur, not how! 
\end{frame}

\begin{frame}\frametitle{Terminology}
Terminology:
 \begin{itemize}
 \item ARL$_0$ - kind of type 1 error. ARL$_0 \; \leftrightarrow \; 1/\alpha$.
 \item Control limit - a quantile, anything above it is ''extreme''
 \item Allowance constant $k$ - how much variation can we allow? $\uparrow\; k\; \rightarrow$ more variation ok.
 \item For simulations/stress testing:
 \begin{itemize}
 \item ARL$_1$ - kind of the power of a test. ARL$_1 \; \leftrightarrow \; 1/\beta$.
 \item ED - expected delay, like ARL$_1$ but change later ''a delay''. Small=good
 \end{itemize}
 \end{itemize}
 \end{frame}

\begin{frame}\frametitle{How to fit the models}
\begin{enumerate}
\item Estimate or specify machine profile, $\boldsymbol{\mu}_0$ and $\Sigma_0$.
\item Choose type 1 error = choose ARL$_0$. ex. ARL$_0 = 100\; \leftrightarrow \; \alpha=0.01$.
\item Choose $k$. ex. k = 0.3, 0.4 or 0.5
\item Do a lot of simulations to find control limit which fulfills ARL$_0$.
\end{enumerate}
Number of simulations should be large, ex $10^6$. 

\end{frame}

\section[ Desc. of data + EDA]{Description of the data and Exploratory data analysis}
\begin{frame}\frametitle{Description of the data}
Data from 2012 until beginning of 2016. 2012 removed, poor/odd quality control data. 11 operational NGS machines with different characteristics under different run settings. 
\begin{itemize}
\item Two datasets - Tag- and Read level measurements. 
\begin{itemize}
\item Tag level - several measurement per read, one measurement for each tag 
\item Read level - one measurement per read: Multivariate distribution.
\end{itemize}
\item $9$ different quality variables (mean q, error rate,\%tag error, completed run cycles etc.)
\item A Hierachical structure of the flowcells and also a hierachical structure of the machines
\end{itemize}
A total of $\Sexpr{N}$ unique flowcells. Single read/Paired end
\end{frame}

\begin{frame}\frametitle{Hierachical structure of the data}
\begin{center}
\begin{figure}[!ht]
\begin{tikzpicture}[%
	sibling distance=10em,
  	every node/.style = {shape=rectangle, rounded corners,draw,align=center,top color=white, bottom color=blue!20},
    	grandchild/.style={grow=down,xshift=0.5em,anchor=west,
  	  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}},
  	grandchildRight/.style={grow=down,xshift=0.5em,anchor=west,
  	  edge from parent path={(\tikzparentnode.south) |-(\tikzchildnode.west)}},
	level 1/.style={sibling distance=17mm},
	level 2/.style={sibling distance=18mm},
	fill opacity=.9,draw opacity=.5
	]
  \node {Flowcell}
    child { node [level 1] (c1) {lane 1}
    		child [level 2] {node {read 1}
    			child [grandchild, level distance=23mm] { node {Tag C}}
    			child [grandchild, level distance=15mm] { node {Tag B}}
    			child [grandchild, level distance=7mm] { node {Tag A}}}
    		child [level 2] {node {read 2}
    			child [grandchildRight, level distance=23mm] { node {Tag C}}
    			child [grandchildRight, level distance=15mm] { node {Tag B}}
			child [grandchildRight, level distance=7mm] { node {Tag A}}
    		}}
    child [level 1] { node {lane 2} }
	child [level 1] { node {lane 3} }
	child [level 1] { node (c4) {lane 4} }
    child [sibling distance=20mm] { node (c8) {lane 8}
		child [level 2] { node {read 1}
			child [grandchild, level distance=23mm] { node {Tag C}}
    			child [grandchild, level distance=15mm] { node {Tag B}}
    			child [grandchild, level distance=7mm] { node {Tag A}}}
    		child [level 2] {node {read 2}
    			child [grandchildRight, level distance=23mm] { node {Tag C}}
    			child [grandchildRight, level distance=15mm] { node {Tag B}}
			child [grandchildRight, level distance=7mm] { node {Tag A}}}
    		};
 \draw [dotted] (c4) -- (c8);
		\end{tikzpicture}
 \caption{The hierachical structure of data at the lowest level, tag level, of measurement.\label{HirStructure}}
\end{figure}
\end{center}
\end{frame}

\begin{frame}\frametitle{Hierachical structure of the data}
\begin{center}
\begin{figure}[!ht]
\begin{tikzpicture}[%
	sibling distance=10em,
  	every node/.style = {shape=rectangle, rounded corners,draw,align=center,top color=white, bottom color=blue!20},
    	grandchild/.style={grow=down,xshift=0.5em,anchor=west,
  	  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}},
  	grandchildRight/.style={grow=down,xshift=0.5em,anchor=west,
  	  edge from parent path={(\tikzparentnode.south) |-(\tikzchildnode.west)}},
	level 1/.style={sibling distance=17mm},
	level 2/.style={sibling distance=18mm},
	fill opacity=.9,draw opacity=.5
	]
  \node {Flowcell}
    child { node [level 1] (c1) {lane 1}
    		child [level 2] {node {read 1}}
    		child [level 2] {node {read 2}}
    		}
    child [level 1] { node {lane 2}}
	child [level 1] { node {lane 3}}
	child [level 1] { node (c4) {lane 4}}
    child [sibling distance=20mm] { node (c8) {lane 8}
		child [level 2] { node {read 1}}
    		child [level 2] {node {read 2}}
    		};
 \draw [dotted] (c4) -- (c8);
		\end{tikzpicture}
 \caption{The hierachical structure of data at the read level of measurement.}
\end{figure}
\end{center}
\end{frame}

 \begin{frame}\frametitle{Completed run cycles}
 \begin{itemize}
 \item Only data on \textit{completed run cycles}, NOT the actual run setting! 
 \end{itemize}
 \pause

 \textbf{Assumption:}
 \pause
A run (ex. paired end v4) performed on 126 (125+1) cycles can result in \textbf{at most} 125 completed run cycles and \textbf{atleast} 120 completed run cycles.

\textbf{HiSeq 6}: cycle 126 paired end has most data for read level. Will be used for creating profile!
\end{frame}

\subsection{Read level figures}
\begin{frame}\frametitle{Comparing HiSeq machines - 126 cycles paired end.}
<<MeanFigure, fig.cap="Figure containing the mean and standard deviation of mean q values in each lane/read.", fig.height=4>>=
Cycl <- c(102,126)
 meanQ_Hiseq4 <- ExtractBotLvlTimeseries(c("mean_q"),"HiSeq 4",All.df.reduced) %>%
    filter(cycles>=Cycl[1],
           cycles<=Cycl[2]) %>%
   # now remove those corresponding to rapid runs on the same cycle level, these only use 2 lanes and have NA on the rest
   na.omit() %>%
   select(grep("mean", colnames(.)))

 meanQ_Hiseq4 <- data.frame("Mean"=colMeans(meanQ_Hiseq4),
                            "sd"=apply(meanQ_Hiseq4,2, sd),
                            "lane_read"=as.factor(colnames(meanQ_Hiseq4)),
                            "Machine"=as.factor("HiSeq 4")) %>%
   melt(measure.vars=c("Mean"))

 meanQ_Hiseq5 <- ExtractBotLvlTimeseries(c("mean_q"),"HiSeq 5",All.df.reduced) %>%
    filter(cycles>=Cycl[1],
           cycles<=Cycl[2]) %>%
   # now remove those corresponding to rapid runs on the same cycle level, these only use 2 lanes and have NA on the rest
   na.omit() %>%
   select(grep("mean", colnames(.)))

 meanQ_Hiseq5 <- data.frame("Mean"=colMeans(meanQ_Hiseq5),
                            "sd"=apply(meanQ_Hiseq5,2, sd),
                            "lane_read"=as.factor(colnames(meanQ_Hiseq5)),
                            "Machine"=as.factor("HiSeq 5")) %>%
   melt(measure.vars=c("Mean"))

 meanQ_Hiseq6 <- ExtractBotLvlTimeseries(c("mean_q"),"HiSeq 6",All.df.reduced) %>%
    filter(cycles>=Cycl[1],
           cycles<=Cycl[2]) %>%
   # now remove those corresponding to rapid runs on the same cycle level, these only use 2 lanes and have NA on the rest
   na.omit() %>%
   select(grep("mean", colnames(.)))

 meanQ_Hiseq6 <- data.frame("Mean"=colMeans(meanQ_Hiseq6),
                            "sd"=apply(meanQ_Hiseq6,2, sd),
                            "lane_read"=as.factor(colnames(meanQ_Hiseq6)),
                            "Machine"=as.factor("HiSeq 6")) %>%
   melt(measure.vars=c("Mean"))


 ggplot(rbind(meanQ_Hiseq4, meanQ_Hiseq5, meanQ_Hiseq6),
        aes(y=value, x=lane_read, color=Machine)) +
   geom_point(aes(fill="Mean"), size=2.5, position=position_dodge(width=0.5)) +
   geom_errorbar(aes(ymax=value+sd, ymin=value-sd, width=0.2, fill="Std."), alpha=0.5, position=position_dodge(width=0.5)) +
   coord_flip() +
   theme_bw() +
   scale_color_brewer(type = "qual", palette=6) +
   scale_fill_manual("",
                     values=c("black","red")) +
   guides(fill=guide_legend(override.aes=list(shape=c(16,NA),
                                              linetype=c(0,12)))) +
   ylab("")
@
\end{frame}

\begin{frame}\frametitle{Read level - Spearman correlation matrix}
 <<ReadlvlCor, fig.cap="Spearman correlation matrix of HiSeq 6 Read level measurements, 126 cycles paired end">>=
HiSeq6.botlvl.series <- ExtractBotLvlTimeseries(c("mean_q","pct_q30","error_rate","raw_clusters","raw_density","pf_clusters","pf_density"),"HiSeq 6",All.df.reduced)
 ## Extract "High output v4" runs: 102-126 cycles using 8 lanes
 v4.HiSeq6.botlvl.series <- filter(HiSeq6.botlvl.series,
                                   cycles>=Cycl[1],
                                   cycles<=Cycl[2]) %>%
   # now remove those corresponding to rapid runs on the same cycle level, these only use 2 lanes and have NA on the rest
   na.omit()

 ggp <- VizCor(v4.HiSeq6.botlvl.series[,-c(1:3)], method="spearman",title="")
N <- ncol(v4.HiSeq6.botlvl.series)

tmpFUN <- function(x) return (cbind(c(2+8*(1+2*x)),c(N-8*(1+2*x))))
df.tmp <- tmpFUN(seq(0,6))

df.tmp <- data.frame(TEXT=c("Error rate","Mean Q","Percent q30","PF clusters","PF density","Raw clusters","Raw density"),df.tmp)

ggp <- ggp + 
   theme(axis.text.x = element_blank(),
          axis.text.y = element_blank()) 

# add text to picture
for (i in 1:nrow(df.tmp)){
  ggp <- ggp + 
   geom_text(x=df.tmp[i,2], y=df.tmp[i,3],label=df.tmp[i,1], 
             angle=-45,size=3.2,family="Times") 
}
tmpFUN <- function(x) return(cbind(N-(2+16*x)-1/2,16*x+1/2))
df.tmp <- tmpFUN(1:7) %>% as.data.frame()  
# Draw lines to create sections
for (i in 1:nrow(df.tmp)){
  ggp <- ggp + 
    geom_segment(y=df.tmp[i,1], x=0.5, xend=df.tmp[i,2], yend=df.tmp[i,1], color="#0000004D", size=0.2) +
    geom_segment(x=df.tmp[i,1], y=0.5, xend=df.tmp[i,1], yend=df.tmp[i,2], color="#0000004D", size=0.2) 
}
# print
ggp
# remove
rm(df.tmp, tmpFUN)
 @
\end{frame}
\subsection{Summary of read/tag level measurements}
\begin{frame}\frametitle{Summary}
The structure of the quality control data is very complicated.
\begin{itemize}
\item Want to model at the lowest level (Tag-level). Difference in observations, complicated! Read-level? 
\item The different machine setting provide another complexity to the problem.
\item In terms of mean q, the machines are different! Not true for error rate. 
\item Finding: Percent tag err.= 0 $\rightarrow$ error rate$>0$ in datasets, wrong? 
\end{itemize}
\end{frame}

\subsection{Transformation to normality}
\begin{frame}\frametitle{Modelling - Solution and transform data}

Monitor Read-level! 

Use mean q, error rate and percent q30 for our modelling example.

$$
\mathbf{X} = (X_{mean\_ q\_ 1\_ 1},X_{ErrRate\_ q\_ 1\_ 1},X_{Pctq30\_ q\_ 1\_ 1},X_{mean\_ q\_ 1\_ 2},..., X_{Pctq30\_ q\_ 8\_ 2})
$$

Can the data be assumed to follow a multivariate normal distribution? No... $\rightarrow$ Transform! \textbf{Assume} $\mathbf{X}^*\sim \mathcal{N}_p(\boldsymbol{\mu}_0,\Sigma_0)$.
\end{frame}
 
% \begin{frame}\frametitle{Normality assumption and different transformations}
%  Box-Cox transformation together with Guerro method for variables on positive real line. Box-Cox transformation:
%  $$
%  Y = \begin{cases}
%  \frac{X^{\lambda}-1}{\lambda}, \text{ if } \lambda\neq 0 \\
%  \log X, \text{ else.}
%  \end{cases}
%  $$
%  estimate $\lambda$ using Guerro method. 
%  
% For variables with limited support (i.e. (0,1)) $\rightarrow$ quantile normal function.
% $$ Y = \Phi^{-1}(X)
% $$ where $\Phi^{-1}(\cdot)$ is the standard normal quantile function.
% \end{frame}

\section{Results}
\subsection{Results - Simulation study}
 
\begin{frame}\frametitle{Stress testing}
Simulation study of two different scenarios. How quickly can we detect changes in profile? Will show change in $\boldsymbol{\mu}_0$. 
 \begin{itemize}
 \item Scenario 1. Lane 1 shows worse behaviour (all variables): all change according to $\delta$
 \item Scenario 2. The error rate shows worse performance in lane 1: change according to $\delta$
 \end{itemize}
 \pause
 Performance measures:
 \begin{enumerate}
 \item ARL$_1$ (MCUSUM, Hotelling $T^2$)
 \item Expected delay, 20 profile runs before machine breaks (MCUSUM)
 \end{enumerate}
\end{frame}

 <<LoadData>>=
 load("../Data/WishartH.Rdata")
 load("../Data/meanH.Rdata")
 load("../Data/Case1Mean.Rdata")
 load("../Data/Case2Mean.Rdata")
 load("../Data/ICdata.Rdata")
 load("../Data/LambdaAndXtable.Rdata")
 load("../Data/CPDsims.Rdata")
 # IC parameters
 K <- 100
 OrgOrder <- colnames(TransformedData)
 # divide by a constant!
 TransformedData[,1:ncol(TransformedData) %in% grep("mean",OrgOrder)] <- TransformedData[,1:ncol(TransformedData) %in% grep("mean",OrgOrder)]/K

 M <- nrow(TransformedData)

 mu0 <- colMeans(TransformedData)
 Sigma0 <- var(TransformedData)*(M-1)/M

 p <- ncol(TransformedData)
 alpha <- 0.01
 QuantileHot <- p*(M-1)*(M+1)/((M-p)*M) * qf(1-alpha, p, M-p)
 source("../FunctionsAndRcpp/mysqlScript.R")
 source("../FunctionsAndRcpp/BotlvlSeriesExtraction.R")
 # C++ Functions
 sourceCpp("../FunctionsAndRcpp/RcppCPDestimation.cpp",showOutput=FALSE, verbose = FALSE)
 sourceCpp("../FunctionsAndRcpp/RcppHotellingT2.cpp",showOutput=FALSE, verbose = FALSE)
 sourceCpp("../FunctionsAndRcpp/RcppMCUSUM.cpp",showOutput=FALSE, verbose = FALSE)
 sourceCpp("../FunctionsAndRcpp/RcppWishart.cpp",showOutput=FALSE, verbose = FALSE)
 # What types of cycles
Cycl <- c(102,126)
 # what variables to extract
 vars <- c("mean_q","pct_q30","error_rate")
 ###### Run on different type of run, cycles are different!!!!!!
 Hiseq3.read <- ExtractBotLvlTimeseries(variable = vars,"HiSeq 3", All.df.reduced) %>%
   na.omit()
 ###### Same type etc
 Hiseq4.read <- ExtractBotLvlTimeseries(variable = vars,"HiSeq 4", All.df.reduced) %>%
   filter(cycles < Cycl[2],cycles > Cycl[1]) %>%
   na.omit()
 ###### Same type etc
 Hiseq5.read <- ExtractBotLvlTimeseries(variable = vars,"HiSeq 5", All.df.reduced) %>%
   filter(cycles < Cycl[2],cycles > Cycl[1]) %>%
   na.omit()
 #### Remove unwanted stuff
 rm(t2,t4,df.sample.results,All.df,All.df.reduced, All.nas,Cycl)

 get_legend <-function(myggplot){
   tmp <- ggplot_gtable(ggplot_build(myggplot))
   leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
   legend <- tmp$grobs[[leg]]
   return(legend)
 }
 @

<<TransformData, cache=TRUE>>=
 TransformNewData <- function(x_new,lambda){
   # Function which transforms new data using a Box-Cox transformation, together with previously estimated
   # lambdas, and the standard normal quantile function.

   # Args:
   # x: new observations or observation.
   # lambda: vector containing transformation parameter for BoxCox transform.
   # mu0: transformed IC data mean
   # Sigma0: transformed IC covariance matrix

   # BoxCox transformation.
   if (nrow(x_new)>1) # is this one observation or a matrix?
   {
     x_trans <- matrix(nrow=dim(x_new)[1], ncol=dim(x_new)[2])
       for (i in 1:ncol(x_new)){
         x_trans[,i]  <- unlist(forecast::BoxCox(x_new[,i],lambda = lambda[i]))
     }
   }
   else
   {
     x_trans <- c()
     for (i in 1:length(x_new)){
       x_trans[i]  <- forecast::BoxCox(x_new[i],lambda = lambda[i])
     }
   }
   return(x_trans)
 }

 TransAndDivide <- function(x) {
   tmp.names <- colnames(x)
   PCT <- grep("pct", tmp.names)

   tmp.ret <- x

   tmp.ret[,!1:ncol(x) %in% PCT] <- TransformNewData(x[,!1:ncol(x) %in% PCT], lambda = Lambdas)

   tmp.ret[,grep("mean",tmp.names)] <- tmp.ret[,grep("mean",tmp.names)]/K

   tmp.ret[,1:ncol(x) %in% PCT] <- apply(x[,1:ncol(x) %in% PCT],2,function(x) qnorm(x))

   return(tmp.ret)
 }
 K <- 100
 Hiseq3.Trans <- TransAndDivide(Hiseq3.read[,-c(1:3)])
 Hiseq4.Trans <- TransAndDivide(Hiseq4.read[,-c(1:3)])
 Hiseq5.Trans <- TransAndDivide(Hiseq5.read[,-c(1:3)])

@
\begin{frame}\frametitle{Scenario 1 - All variables, lane 1 change}
<<Scenario1mean, fig.height=3.5, fig.cap="Scenario 1. ARL1 and ED for the MCUSUM model for different delta. ">>=
 library(ggplot2)
 library(gridExtra)
 ggplot.tmp <- do.call("cbind",ARL1.case1) %>% as.data.frame()
 ggplot.tmp$x <- changeVector.case1
 colnames(ggplot.tmp) <- c(paste0("k",c(0.3,0.4,0.5)), "x")
 p1 <- ggplot(ggplot.tmp)+
   geom_line(aes(y=k0.3,x=x, linetype="solid")) +
   geom_line(aes(y=k0.4,x=x, linetype="dashed")) +
   geom_line(aes(y=k0.5,x=x, linetype="dotdash")) +
   ylab(expression(ARL[1])) +
   xlab(expression(delta)) +
   scale_linetype("Allowance \n constant, k", labels=paste0("0.",3:5)) +
   theme_bw() +
   theme(legend.position="right")
 
 
 ggplot.tmp <- do.call("cbind",ED.case1) %>% as.data.frame()
 ggplot.tmp$x <- changeVector.case1
 colnames(ggplot.tmp) <- c(paste0("k",c(0.3,0.4,0.5)), "x")
 
 p2 <- ggplot(ggplot.tmp) +
   geom_line(aes(y=k0.3,x=x), linetype=1) +
   geom_line(aes(y=k0.4,x=x), linetype=2) +
   geom_line(aes(y=k0.5,x=x), linetype=3) +
   theme_bw() +
   ylab("ED") +
   xlab(expression(delta)) +
   theme(legend.position="none")
 p3 <- get_legend(p1)
 p1 <- p1 + theme(legend.position="none")
 
 grid.arrange(p1,p2,p3, ncol=3, widths=c(2.3, 2.3, 0.8))
 @
Hotelling's did not discover any of the changes (ARL$_1\geq 500$).
\end{frame}

\begin{frame}\frametitle{Scenario 2 - change in the error rate by $\delta$}
<<Scenario2mean, fig.height=3.5, fig.cap="Scenario 2. ARL1 and ED for the MCUSUM model for different delta.">>=
library(ggplot2)
library(gridExtra)
ggplot.tmp <- do.call("cbind",ARL1.case2) %>% as.data.frame()
ggplot.tmp$x <- changeVector.case2
colnames(ggplot.tmp) <- c(paste0("k",c(0.3,0.4,0.5)), "x")
p1 <- ggplot(ggplot.tmp)+
 geom_line(aes(y=k0.3,x=x, linetype="solid")) +
 geom_line(aes(y=k0.4,x=x, linetype="dashed")) +
 geom_line(aes(y=k0.5,x=x, linetype="dotdash")) +
 ylab(expression(ARL[1])) +
 xlab(expression(delta)) +
 scale_linetype("Allowance \n constant, k", labels=paste0("0.",3:5)) +
 theme_bw() +
 theme(legend.position="right")


ggplot.tmp <- do.call("cbind",ED.case2) %>% as.data.frame()
ggplot.tmp$x <- changeVector.case2
colnames(ggplot.tmp) <- c(paste0("k",c(0.3,0.4,0.5)), "x")

p2 <- ggplot(ggplot.tmp) +
 geom_line(aes(y=k0.3,x=x), linetype=1) +
 geom_line(aes(y=k0.4,x=x), linetype=2) +
 geom_line(aes(y=k0.5,x=x), linetype=3) +
 theme_bw() +
 ylab("ED") +
 xlab(expression(delta)) +
 theme(legend.position="none")
p3 <- get_legend(p1)
p1 <- p1 + theme(legend.position="none")
 
grid.arrange(p1,p2,p3, ncol=3, widths=c(2.3, 2.3, 0.8))
@
Hotelling's did not discover any of the changes (ARL$_1\geq 500$).
\end{frame}

\begin{frame}\frametitle{CPD - estimate change point}
\begin{enumerate}
\item Simulate 20 runs according to profile
\item Simulate the number of runs it took us to discover the change (according to ED)
\item estimate change point (21st run)
\item D = estimated changepoint - simulated changepoint.
\end{enumerate}
Repeat $10^5$ times, take average. 
\end{frame}
<<Tableprep>>=
#library(xtable)
Scenario1 <- data.frame("delta"=CPDchangeVector.case1, "D"=Case1.CPD)
Scenario2 <- data.frame("delta"=changeVector.case2, "D"=Case2.CPD)
xtable(t(Scenario2))
@
\begin{frame}\frametitle{CPD - simulations}
<<CPDfig, fig.height=4, fig.cap="Offset average estimate of the change-point detection model." >>=
p1 <- ggplot(Scenario1,aes(x=delta,y=D)) +
  geom_line(linetype="dashed") +
  geom_point() +
  theme_bw() +
  xlab(expression(delta)) +
  ggtitle("Scenario 1")
p2 <- ggplot(Scenario2,aes(x=delta,y=D)) +
  geom_line(linetype="dashed") +
  geom_point()+
  theme_bw() +
  xlab(expression(delta)) +
  ggtitle("Scenario 2")

grid.arrange(p1,p2,ncol=2)
@
\end{frame}

\begin{frame}\frametitle{Summary of stress test}
\begin{itemize}
\item Quick to detect change in a whole lane
\item Not so quick to detect changes in one variable. 
\item CPD model, poor for small $\delta$. Result of unbalanced sample?
\end{itemize}
\end{frame}

\subsection{Results - Application on HiSeq quality control data.}

\begin{frame}\frametitle{How do models work in practice}
\begin{itemize}
\item Transform new data according to transformation methods.
\item Use Hotelling + MCUSUM models so see if new data fits profile.
\item Anything above control limit indicates change in profile.
\end{itemize}
\textbf{Note:} Transformation parameters are estimated from HiSeq 6 data and then used to transform HiSeq 3, 4 and 5 data.
\end{frame}
<<HotellingPhase2>>=
HiSeq3.Hots <- data.frame("HiSeq3"=apply(Hiseq3.Trans, 1, function(x) HotellingT2(unlist(x),mu0=mu0,Sigma0=Sigma0)),
                           "x"=1:nrow(Hiseq3.Trans),
                           "Alarm"=as.factor(ifelse(apply(Hiseq3.Trans, 1, function(x) HotellingT2(unlist(x),mu0=mu0,Sigma0=Sigma0))>QuantileHot,1,0)))
HiSeq4.Hots <- data.frame("HiSeq4"=apply(Hiseq4.Trans, 1, function(x) HotellingT2(unlist(x),mu0=mu0,Sigma0=Sigma0)),
                           "x"=1:nrow(Hiseq4.Trans),
                           "Alarm"=as.factor(ifelse(apply(Hiseq4.Trans, 1, function(x) HotellingT2(unlist(x),mu0=mu0,Sigma0=Sigma0))>QuantileHot,1,0)))
HiSeq5.Hots <- data.frame("HiSeq5"=apply(Hiseq5.Trans, 1, function(x) HotellingT2(unlist(x),mu0=mu0,Sigma0=Sigma0)),
                           "x"=1:nrow(Hiseq5.Trans),
                           "Alarm"=as.factor(ifelse(apply(Hiseq5.Trans, 1, function(x) HotellingT2(unlist(x),mu0=mu0,Sigma0=Sigma0))>QuantileHot,1,0)))
@

\begin{frame}\frametitle{How do models work - simulated example of Hotelling}
<<ExampleHotelling, fig.cap="Example of Hotellings T2 statistic.", fig.height=3.5>>=
set.seed("1212")
Ok_data <- MASS::mvrnorm(30,mu0,Sigma0)
Ok_data <- apply(Ok_data,1,function(x)HotellingT2(x_new=unlist(x),mu0,Sigma0 = Sigma0))
Bad_data <- MASS::mvrnorm(30,mu0+1,Sigma0)
Bad_data <- apply(Bad_data,1, function(x) HotellingT2(x_new=unlist(x),mu0,Sigma0 = Sigma0))

ggplot(data.frame("Hot"=c(Ok_data,Bad_data), "x"=1:length(c(Ok_data,Bad_data)))) +
  geom_point(aes(x=x,y=Hot)) +
  geom_hline(aes(yintercept=QuantileHot)) +
  theme_bw() +
  geom_vline(xintercept=30.5, alpha=0.3) +
  geom_text(label="No change", x=15, y =500, alpha=0.5) +
  geom_text(label="Change", x=45, y=500, alpha=0.5) +
  geom_text(label="Control limit",x=10,y=200) +
  geom_segment(aes(xend=14, yend=QuantileHot-10, x=12, y=210), arrow=arrow(length=unit(0.3,"cm"))) +
  ylab("value") +
  xlab("Order of appearance")
@
\end{frame}
 
\begin{frame}\frametitle{Hotelling's $T^2$ statistic}
 <<HotellingsPicture, fig.cap="Hotellings T statistic for HiSeq 3, 4 and 5. HiSeq 3 has no paired end 126 cycle runs!", fig.height=4>>=
 p1 <- ggplot() +
   geom_point(aes(x=x,y=HiSeq3, color=Alarm), data=HiSeq3.Hots) +
   geom_hline(yintercept=QuantileHot, alpha=0.6) +
   ylab("value") +
   xlab("time") +
   theme_bw() +
   scale_color_manual("Yes", values = c("#4e4eff","#ff4e4e"), breaks=c("Alarm","No Alarm")) +
   ggtitle("HiSeq 3")

 p2 <- ggplot() +
   geom_point(aes(x=x,y=HiSeq4, color=Alarm), data=HiSeq4.Hots) +
   geom_hline(yintercept=QuantileHot) +
   ylab("value") +
   xlab("time") +
   theme_bw() +
   scale_color_manual("", values = c("#4e4eff","#ff4e4e"), breaks=c("Alarm","No Alarm"))+
   ggtitle("HiSeq 4")
 # lane 2 shows "some kind" of deviating behaviour otherwise data indicates that it is good!

 p3 <- ggplot() +
   geom_point(aes(x=x,y=HiSeq5, color=Alarm), data=HiSeq5.Hots) +
   geom_hline(yintercept=QuantileHot) +
   ylab("value") +
   xlab("time") +
   theme_bw() +
   scale_color_manual("", values = c("#4e4eff","#ff4e4e"), breaks=c("Alarm","No Alarm")) +
   ggtitle("HiSeq 5")

 grid.arrange(p1,p2,p3,ncol=3)
 rm(p1,p2,p3)
 @
\end{frame}

 <<MCUSUMtrans, cache=TRUE>>=
 k <- 0.3
 # covH <- H_ListSigma[[1]]$Intervals %>%
 #   na.omit() %>%
 #   tail(1) %>%
 #   mean()

 meanH <- H_Listmean[[1]]$Intervals %>%
   na.omit() %>%
   tail(1) %>%
   mean()
 ConstructMeanChartingStatistic <- function(data) {
   # function calculating the charting statistic of the MCUSUM mean
   ret <- c()
   Sold <- rep(0, ncol(Sigma0))


   for(i in 1:nrow(data)){
     tmp <- MCUSUM(Snew=unlist(data[i,]),Sold = Sold, mu0=mu0, Sigma0 = Sigma0, k=k)

     Sold <- tmp$Snew
     Cstat <- tmp$Cstatistic
     ret <- c(ret,Cstat)
   }
   return(ret)
 }
 ### Wishart transformation
 # ConstructWishartChartingStatistic<- function(data) {
 #   # Function which construct the charting statistic for the Wishart distribution.
 # 
 #   # Args:
 #   # data: (data.frame) data.frame on the same format as the initial data which was used to estimate mu0 and sigma0.
 #   data <- Hiseq4.Trans
 #   ret <- c()
 #   Sold <- rep(0, ncol(Sigma0)-1)
 # 
 #   for (j in 1:nrow(data)){
 #     tmp <- lapply(1:ncol(Hiseq3.Trans),function(x) TransformObsWishart(observation=unlist(data[j,]),i=x,mu0=mu0,sigma0 = Sigma0))
 #     WhichMaxStatistic <- lapply(tmp, function(x) MCUSUM(Snew=x,Sold=Sold,mu0=rep(0,ncol(Sigma0)-1),Sigma0 = diag(ncol(Sigma0)-1), k=k)$Cstatistic) %>%
 #       unlist() %>%
 #       which.max()
 # 
 #     tmp <- MCUSUM(Snew=tmp[[WhichMaxStatistic]],Sold=Sold ,mu0=rep(0,ncol(Sigma0)-1), Sigma0 = diag(ncol(Sigma0)-1), k=k)
 #     Sold <- tmp$Snew
 # 
 #     Hstatistic <- tmp$Cstatistic
 #     ret <- c(ret,Hstatistic)
 #   }
 #   return(ret)
 # }
 #### MCUSUM mean
 Mean_HiSeq4 <-  data.frame("HiSeq4"=ConstructMeanChartingStatistic(Hiseq4.Trans),
                            "x"=1:nrow(Hiseq4.Trans),
                            "Alarm"=as.factor(ifelse(ConstructMeanChartingStatistic(Hiseq4.Trans)>meanH,1,0)))

 Mean_HiSeq5 <-  data.frame("HiSeq5"=ConstructMeanChartingStatistic(Hiseq5.Trans),
                            "x"=1:nrow(Hiseq5.Trans),
                            "Alarm"=as.factor(ifelse(ConstructMeanChartingStatistic(Hiseq5.Trans)>meanH,1,0)))
 #### MCUSUM Wishart.
 # Wishart_Hiseq4 <- data.frame("HiSeq4"=ConstructWishartChartingStatistic(Hiseq4.Trans),
 #                              "x"=1:nrow(Hiseq4.Trans),
 #                              "Alarm"=as.factor(ifelse(ConstructWishartChartingStatistic(Hiseq4.Trans)>covH,1,0)))
 # 
 # 
 # Wishart_Hiseq5 <- data.frame("HiSeq5"=ConstructWishartChartingStatistic(Hiseq5.Trans),
 #                              "x"=1:nrow(Hiseq5.Trans),
 #                              "Alarm"=as.factor(ifelse(ConstructWishartChartingStatistic(Hiseq5.Trans)>covH,1,0)))
 @

\begin{frame}\frametitle{MCUSUM - HiSeq 4 and 5 cycle 126 paired end.}
 <<MCUSUMmean1, fig.cap="MCUSUM model for the mean tested on transformed HiSeq 4 and 5 data.", fig.height=4>>=
 p2 <- ggplot(Mean_HiSeq4) +
   geom_point(aes(x=x,y=HiSeq4, color=Alarm)) +
   geom_hline(yintercept=meanH, alpha=0.6) +
   ylab("value") +
   xlab("time") +
   theme_bw() +
   scale_color_brewer("Change",type = "qual", palette=6, direction=-1) +
   ggtitle("HiSeq 4") 
 
 p3 <- ggplot(Mean_HiSeq5) +
   geom_point(aes(x=x,y=HiSeq5, color=Alarm)) +
   geom_hline(yintercept=meanH, alpha=0.6) +
   ylab("value") +
   xlab("time") +
   theme_bw() +
   scale_color_brewer(type = "qual", palette=6, direction=-1)+
   ggtitle("HiSeq 5") + 
   theme(legend.position="none")
 
 p4 <- get_legend(p2)
 p2 <- p2 + theme(legend.position="none")
 grid.arrange(p2,p3,p4,ncol=3,widths=c(2.3, 2.3, 0.8))
 rm(p2,p3,p4)
 @
\end{frame}
 
 \section{Summary}
 \begin{frame}\frametitle{Summary}
 \begin{itemize}
 \item Constructed two models for detecting transient and large or persistent and small changes. CPD model for estimating change-points.
 \begin{itemize}
 \item Persistent changes in mean presented here. 
 \item Covariance is also considered in thesis.
 \end{itemize}
 \item Constructed models detect changes in the mean and covariance for all HiSeq machines. Why? \pause
 Probably transformation or possibly not the same quality on average!
 \item Trends? Can be read from the MCUSUM model. 
 \end{itemize}
 \end{frame}

 \section{Discussion}
 \begin{frame}\frametitle{Assumptions and complications with the suggested methods}
 \begin{itemize}
 \item Assumptions of normality and independence, are they violated? Short answer, yes. Implications?
 \pause
 \begin{itemize}
 \item MCUSUM: Control limit may be too small/large, ARL$_0$/ARL$_1$ misspecified. Solution?
 \item Hotellings: Robust against deviations of the assumption of normality. 
 \end{itemize}
\item Dependence between runs, different settings (High output/rapid, single/paired end) $\rightarrow$ create profile for each setting. Solution? 
 \end{itemize}
 
 \end{frame}

 \begin{frame}\frametitle{Other methods?}
 \begin{itemize}
 \item Non-parametric multivariate methods, have not found any methods on specifying the control limits except for bootstrap based (need large data sets, we have small sets.)
 \item Reinforcement learning could work but also demand large data sets.
 \end{itemize}
 \end{frame}

\begin{frame}
\begin{center}
{\Large Thank you!} 
\newline
\end{center}
Thanks to the SNP\&SEQ platform for giving me this opportunity, my supervisor Johan D. for his support/guidance and last all of those who have helped me in this process! 
\end{frame}

\section{Optional - MATH!}

\begin{frame}\frametitle{Hotelling's $T^2$ statistic}
Let $\mathbf{X}_t$ be the $t$'th observation. Under the null hyp. $\mathbf{X}_t \sim \mathcal{N}_p(\boldsymbol{\mu}_0,\Sigma_0)$, and let
$$
T^2_{2,t} = (\mathbf{X}_t-\boldsymbol{\mu}_0)'\boldsymbol{\Sigma}^{-1}_0(\mathbf{X}_t-\boldsymbol{\mu}_0).
$$ 
then
$$
\frac{(M-p)M}{p(M-1)(M+1)} T^2_{2,t} \sim \mathcal{F}_{p,M-p}
$$
if 
$$
T^2_{2,t}>\frac{p(M-1)(M+1)}{(M-p)M}\mathcal{F}_{p,M-p}$$
signal change!
\end{frame}

\begin{frame}\frametitle{MCUSUM statistic}
Let $\mathbf{S}_0=\mathbf{0}$ and then. 
\begin{align}
&C_t=\sqrt{(\mathbf{S}_{t-1}+\mathbf{X}_t-\boldsymbol{\mu}_0)'\boldsymbol{\Sigma}^{-1}_0
(\mathbf{S}_{t-1}+\mathbf{X}_t-\boldsymbol{\mu}_0)}\label{MCUSUM} &\\ 
&\mathbf{S}_t=\begin{cases}
\mathbf{0} & \text{if} \; C_t \leq k \\
(\mathbf{S}_{t-1}+\mathbf{X}_t-\boldsymbol{\mu}_0)(1-k/C_t) & \text{otherwise}
\end{cases} \label{MCUSUM2} &
\end{align}
where $k$ is the allowance constant. Let 
\begin{equation}\label{Ht}
H_t=\sqrt{\mathbf{S}_t'\boldsymbol{\Sigma}^{-1}_0 \mathbf{S}_t},
\end{equation} 
if $H_t>h$ signal a change.
\end{frame}

\end{document}

% 
% \begin{description}[align = right]
%  \item Problem:
% \end{description}
% \end{frame}